# -*- coding: utf-8 -*-
"""kaju new ann lstm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fArR1xwel_MFFSwN6IsrUQxQto0WKrbP
"""

import os
import librosa
import numpy as np
import matplotlib.pyplot as plt
import librosa.display

filename= '/content/drive/MyDrive/pizza/pizza_10_01.wav'

import IPython.display as ipd

plt.figure(figsize=(10,5))
data, sample_rate = librosa.load(filename)
librosa.display.waveshow(data,sr=sample_rate)
ipd.Audio(filename)

sample_rate

data

mfccs = librosa.feature.mfcc(y=data, sr=sample_rate,n_mfcc=40)

mfccs

mfccs.shape

dataset_path = r'/content/drive/MyDrive'

catagories = [ 'pizza','burger', 'chips', 'carrots', 'soup', 'grapes']
data = []

for catagory in catagories:
  catagory_folder = os.path.join(dataset_path, catagory)
  label = catagories.index(catagory)
  for filename in os.listdir(catagory_folder):
      if filename.endswith('.wav'):
          audio_file = os.path.join(catagory_folder, filename)
          data.append([audio_file, label])

len(data)

import random

random.shuffle(data)

x = []
y = []

for features, labels in data:
  x.append(features)
  y.append(labels)

def extract_mfcc_features(audio_file, n_mfcc=13):
  audio, sr = librosa.load(audio_file, sr=None)
  mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)
  return np.mean(mfccs, axis=1)

x = np.array([extract_mfcc_features(features) for features in x])

x.shape

y = np.array(y)

y



"""***pickle***"""

import pickle

pickle.dump(x, open ('eating_x.pkl','wb'))
pickle.dump(y, open ('eating_y.pkl','wb'))

x_read = pickle.load(open('eating_x.pkl', 'rb'))

x_read.shape



"""**test** **train**"""

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)

x_train.shape, x_test.shape, y_test.shape, y_train.shape



"""**ANN**"""

import tensorflow as tf
import keras
from keras import layers

ANN = tf.keras.Sequential([
    layers.Dense(128,input_shape=(13,),activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(32, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(6, activation='softmax')
])

ANN.summary()

ANN.compile(optimizer='adam',
            loss='sparse_catagorical_crossentropy',
            metrics=['accuracy'])

history = ANN.fit(x_train, y_train, epochs=100, validation_data=(x_test,y_test))

ANN.evaluate(x_test, y_test)

from sklearn.metrics import accuracy_score

y_pred = ANN.predict(x_test)

y_pred = np.argmax(y_pred, axis=1)

y_pred

print(accuracy_score(y_test, y_pred))



"""**LSTM**"""

x_train_lstm = np.expand_dims(x_train, -1)

x_train_lstm.shape



from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

model = Sequential()

model.add(LSTM(128, activation='relu', return_sequences=True, input_shape=(13,1)))
model.add(LSTM(64, activation='relu', return_sequences=True))
model.add(LSTM(32, activation='relu'))

model.add(Dense(6, activation='softmax'))

model.compile(optimizer='adam', loss='sparse_catagorical_crossentropy', metrics=['accuracy'])

model.summary()

#lstm_history = model.fit(x_train, y_train, epochs=400, validation_data= (x_test,y_test))

#model.evaluate(x_test, y_test)

y_pred = model.predict(x_test)

y_pred = np.argmax(y_pred, axis=1)

y_pred

print(accuracy_score(y_test, y_pred))